---
wave: 2
depends_on: []
files_modified:
  - src/config.py
  - src/main_window.py
autonomous: true
must_haves:
  - MODEL_METADATA dictionary with ram_mb, rtf, description for each model
  - Model dropdown shows "Name — RAM — Description" format
  - Model selection grouped by backend
  - Warning shown for models > 2GB RAM
  - Loading indicator when switching models
---

# Plan 04-05: Enhanced Model Selection

**Objective:** Improve model selection UI with metadata and better information

## Tasks

<task id="04-05-01">
<summary>Add MODEL_METADATA dictionary to config.py</summary>
<details>
- Create MODEL_METADATA dict with keys for all models
- Include fields: ram_mb, rtf, description
- Entries for all Whisper, Sherpa, and Podlodka models
- Example: {"tiny": {"ram_mb": 1000, "rtf": 0.3, "description": "Макс. скорость"}}
</details>
<verification>MODEL_METADATA contains all models with metadata</verification>
</task>

<task id="04-05-02">
<summary>Create model display formatter function</summary>
<details>
- Add `format_model_display(backend: str, model: str) -> str` function
- Format: "{model_name} — {ram}MB RAM — {description}"
- Return formatted string for UI
- Example: "tiny — 1000MB — Макс. скорость"
</details>
<verification>Function returns properly formatted strings</verification>
</task>

<task id="04-05-03">
<summary>Update model dropdown to show metadata</summary>
<details>
- Modify _update_model_options() in SettingsDialog
- Use MODEL_METADATA for display text
- Keep model ID as currentData()
- Group by backend with separator or header
</details>
<verification>Dropdown shows model names with RAM and description</verification>
</task>

<task id="04-05-04">
<summary>Add RAM warning for large models</summary>
<details>
- In _model_changed() handler, check MODEL_METADATA[model].ram_mb
- Show warning if ram_mb > 2000:
  * "⚠️ This model requires ~{ram}MB RAM. May be slow on older systems."
- Use QMessageBox with warning icon
- Allow user to cancel model change
</details>
<verification>Warning appears for models > 2GB</verification>
</task>

<task id="04-05-05">
<summary>Add loading indicator during model switch</summary>
<details>
- Show "Loading model..." in status_label during switch
- Disable model combo during loading
- Re-enable after transcriber.switch_backend() completes
- Handle errors during model loading gracefully
</details>
<verification>UI shows loading state during model change</verification>
</task>

<task id="04-05-06">
<summary>Add current model info display</summary>
<details>
- Add QLabel below model dropdown showing current model info
- Display: "RAM: ~{ram}MB | RTF: {rtf}x"
- Update when model selection changes
- Use muted color for label text
</details>
<verification>Model info appears below dropdown</verification>
</task>

<task id="04-05-07">
<summary>Sort models by RTF within each backend</summary>
<details>
- Order models: fastest first (lowest RTF)
- Consistent ordering across backend switches
- Update model combo population logic
</details>
<verification>Models appear sorted by speed</verification>
</task>

## Success Criteria

- [ ] Model dropdown shows RAM usage and description
- [ ] Large models (>2GB) trigger warning
- [ ] Loading indicator shows during model switch
- [ ] Current model info displays below dropdown
- [ ] Models sorted by speed within each backend

## MODEL_METADATA Structure

```python
MODEL_METADATA = {
    # Whisper models
    "tiny": {"ram_mb": 1000, "rtf": 0.3, "description": "Макс. скорость"},
    "base": {"ram_mb": 1000, "rtf": 0.5, "description": "Быстрый"},
    "small": {"ram_mb": 2000, "rtf": 1.0, "description": "Баланс"},
    "medium": {"ram_mb": 5000, "rtf": 2.0, "description": "Точный"},
    "large-v3-turbo": {"ram_mb": 10000, "rtf": 3.0, "description": "Макс. точность"},
    # Sherpa models
    "giga-am-v2-ru": {"ram_mb": 140, "rtf": 0.1, "description": "Russian (2025)"},
    "giga-am-ru": {"ram_mb": 140, "rtf": 0.1, "description": "Russian (2024)"},
    # Podlodka model
    "podlodka-turbo": {"ram_mb": 1000, "rtf": 0.4, "description": "Ru fine-tuned"},
}
```

## UI Layout

```
┌─ Model ─────────────────────────────────┐
│ [giga-am-v2-ru — 140MB — Russian (2025)] ▼│
│ RAM: ~140MB | RTF: 0.1x                 │
└─────────────────────────────────────────┘
```

## Notes

- Model loading can take 2-10 seconds depending on size
- RTF = Real-Time Factor (1.0 = 1 sec audio processes in 1 sec)
- Lower RTF = faster processing
- Consider adding "Test Speed" button (future)
