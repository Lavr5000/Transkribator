---
phase: 02-noise-reduction-vad
plan: 04
type: execute
wave: 2
depends_on: [02-03]
files_modified:
  - src/backends/whisper_backend.py
  - RemotePackage/src/backends/whisper_backend.py
  - src/backends/podlodka_turbo_backend.py
  - RemotePackage/src/backends/podlodka_turbo_backend.py
  - src/transcriber.py
autonomous: true

must_haves:
  truths:
    - "WhisperBackend использует Silero VAD для детекции речи"
    - "PodlodkaBackend использует Silero VAD для детекции речи"
    - "VAD параметры едины для всех бэкендов (из config)"
    - "VAD результаты согласованы между бэкендами (одинаковая фильтрация тишины)"
  artifacts:
    - path: "src/backends/whisper_backend.py"
      contains: "_vad"
      contains: "OfflineVad"
    - path: "src/backends/podlodka_turbo_backend.py"
      contains: "_vad"
      contains: "OfflineVad"
    - path: "src/transcriber.py"
      contains: "vad_enabled\|vad_threshold\|min_silence"
  key_links:
    - from: "src/backends/whisper_backend.load_model"
      to: "sherpa_onnx.OfflineVad"
      via: "shared VAD initialization pattern"
      pattern: "OfflineVad("
    - from: "src/transcriber.__init__"
      to: "backend VAD config"
      via: "pass VAD params to backends"
      pattern: "vad_enabled\|vad_threshold"
---

<objective>
Implement Silero VAD for all transcription backends (Whisper, Podlodka).

**What:**
Extend Silero VAD integration from SherpaBackend to WhisperBackend and PodlodkaBackend.

**Why:**
VAD benefits apply to all backends: silence removal improves accuracy and reduces processing time. Currently VAD only works in SherpaBackend (from 02-03). Other backends process entire audio including silence, wasting compute and creating false artifacts.

**Output:**
All three backends (Sherpa, Whisper, Podlodka) use Silero VAD with unified configuration from config.py.
</objective>

<execution_context>
@C:\Users\user\.claude\get-shit-done\workflows\execute-plan.md
@C:\Users\user\.claude\get-shit-done\templates\summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-noise-reduction-vad/02-RESEARCH.md
@.planning/phases/02-noise-reduction-vad/02-CONTEXT.md
@.planning/phases/02-noise-reduction-vad/02-03-SUMMARY.md

# Current file locations
C:\Users\user\.claude\0 ProEKTi\Transkribator\src\backends\whisper_backend.py
C:\Users\user\.claude\0 ProEKTi\Transkribator\RemotePackage\src\backends\whisper_backend.py
C:\Users\user\.claude\0 ProEKTi\Transkribator\src\backends\podlodka_turbo_backend.py
C:\Users\user\.claude\0 ProEKTi\Transkribator\RemotePackage\src\backends\podlodka_turbo_backend.py
C:\Users\user\.claude\0 ProEKTi\Transkribator\src\transcriber.py
</context>

<tasks>

<task type="auto">
  <name>Add VAD to WhisperBackend</name>
  <files>src/backends/whisper_backend.py, RemotePackage/src/backends/whisper_backend.py</files>
  <action>
In both whisper_backend.py files:

1. Add imports at top (after existing imports):
```python
from pathlib import Path
import sherpa_onnx
```

2. Add VAD attributes to __init__ after existing attributes (find self._model = None):
```python
# VAD (Voice Activity Detection)
self._vad = None
self._vad_enabled = False  # Set from config
self._vad_threshold = 0.5
self._min_silence_duration_ms = 800
self._min_speech_duration_ms = 500
```

3. Add _get_vad_model_dir method (copy from sherpa_backend.py - identical):
```python
def _get_vad_model_dir(self) -> Path:
    """Get Silero VAD model directory, download if missing."""
    from huggingface_hub import snapshot_download

    vad_dir = Path(__file__).parent.parent.parent / "models" / "sherpa" / "silero-vad"
    vad_dir.mkdir(parents=True, exist_ok=True)

    if not (vad_dir / "v4.onnx").exists():
        try:
            snapshot_download(
                repo_id="csukuangfj/sherpa-onnx-silero-vad",
                local_dir=str(vad_dir),
                local_dir_use_symlinks=False,
            )
        except Exception as e:
            print(f"Failed to download VAD model: {e}")

    return vad_dir
```

4. Update load_model() to initialize VAD (after model loading, around line 50-80):
```python
# Initialize Silero VAD if enabled
if self._vad_enabled:
    try:
        vad_dir = self._get_vad_model_dir()
        self._vad = sherpa_onnx.OfflineVad(
            model_dir=str(vad_dir),
            threshold=self._vad_threshold,
            min_silence_duration=self._min_silence_duration_ms / 1000.0,
            min_speech_duration=self._min_speech_duration_ms / 1000.0,
        )
        print(f"WhisperBackend: VAD initialized")
    except Exception as e:
        print(f"WhisperBackend: Failed to initialize VAD: {e}")
        self._vad = None
```

5. Add VAD filtering to transcribe() method (insert at start after load_model call, around line 150):
```python
def transcribe(self, audio: np.ndarray, sample_rate: int = 16000) -> Tuple[str, float]:
    """Transcribe audio with optional VAD pre-processing."""
    if self._model is None:
        self.load_model()

    start_time = time.time()

    # Apply VAD to filter silence if enabled (before Whisper processing)
    if self._vad_enabled and self._vad is not None:
        try:
            vad_stream = self._vad.create_stream()
            vad_stream.accept_waveform(sample_rate, audio)
            self._vad.compute(vad_stream)

            segments = vad_stream.segments
            if segments:
                speech_segments = []
                for seg in segments:
                    start_sample = int(seg.start * sample_rate)
                    end_sample = int(seg.end * sample_rate)
                    start_sample = max(0, start_sample)
                    end_sample = min(len(audio), end_sample)
                    if end_sample > start_sample:
                        speech_segments.append(audio[start_sample:end_sample])

                if speech_segments:
                    audio = np.concatenate(speech_segments)
                else:
                    return "", 0.0
            else:
                return "", 0.0
        except Exception as e:
            print(f"WhisperBackend: VAD filtering failed: {e}")
            # Continue with original audio on VAD failure

    # Rest of existing transcribe code continues unchanged...
    # (language setting, transcribe call, etc.)
```

DO NOT modify the existing Whisper transcribe() logic - only insert VAD filtering at the start.
  </action>
  <verify>grep -n "OfflineVad\|_get_vad_model_dir\|vad_stream" src/backends/whisper_backend.py RemotePackage/src/backends/whisper_backend.py</verify>
  <done>WhisperBackend has VAD with same pattern as SherpaBackend</done>
</task>

<task type="auto">
  <name>Add VAD to PodlodkaBackend</name>
  <files>src/backends/podlodka_turbo_backend.py, RemotePackage/src/backends/podlodka_turbo_backend.py</files>
  <action>
In both podlodka_turbo_backend.py files:

Apply the SAME pattern as WhisperBackend (task 1):

1. Add imports:
```python
from pathlib import Path
import sherpa_onnx
```

2. Add VAD attributes to __init__:
```python
self._vad = None
self._vad_enabled = False
self._vad_threshold = 0.5
self._min_silence_duration_ms = 800
self._min_speech_duration_ms = 500
```

3. Add _get_vad_model_dir method (identical to WhisperBackend/SherpaBackend)

4. Update load_model() to initialize VAD (after model loading)

5. Add VAD filtering to transcribe() method (at start, after load_model)

The pattern is IDENTICAL to WhisperBackend - only the class name differs.
  </action>
  <verify>grep -n "OfflineVad\|_get_vad_model_dir" src/backends/podlodka_turbo_backend.py RemotePackage/src/backends/podlodka_turbo_backend.py</verify>
  <done>PodlodkaBackend has VAD with same pattern as other backends</done>
</task>

<task type="auto">
  <name>Wire VAD config from Transcriber to backends</name>
  <files>src/transcriber.py</files>
  <action>
Update Transcriber to pass VAD config to all backends:

1. Find where backends are instantiated (look for WhisperBackend(), SherpaBackend(), PodlodkaTurboBackend() calls)

2. Add VAD parameters to each backend instantiation:

For WhisperBackend (around line 30-50):
```python
self.whisper_backend = WhisperBackend(
    model_size=config.model_size,
    device=config.device,
    compute_type=config.compute_type,
    language=config.language,
    # VAD config
    vad_enabled=config.vad_enabled,
    vad_threshold=config.vad_threshold,
    min_silence_duration_ms=config.min_silence_duration_ms,
    min_speech_duration_ms=config.min_speech_duration_ms,
)
```

For SherpaBackend:
```python
self.sherpa_backend = SherpaBackend(
    model_size=config.model_size,
    device=config.device,
    # VAD config
    vad_enabled=config.vad_enabled,
    vad_threshold=config.vad_threshold,
    min_silence_duration_ms=config.min_silence_duration_ms,
    min_speech_duration_ms=config.min_speech_duration_ms,
)
```

For PodlodkaTurboBackend:
```python
self.podlodka_backend = PodlodkaTurboBackend(
    model_size=config.model_size,
    device=config.device,
    compute_type=config.compute_type,
    language=config.language,
    # VAD config
    vad_enabled=config.vad_enabled,
    vad_threshold=config.vad_threshold,
    min_silence_duration_ms=config.min_silence_duration_ms,
    min_speech_duration_ms=config.min_speech_duration_ms,
)
```
  </action>
  <verify>grep -n "vad_enabled=config.vad_enabled" src/transcriber.py</verify>
  <done>Transcriber passes VAD config to all backends</done>
</task>

</tasks>

<verification>
After implementation:
1. grep confirms OfflineVad import in whisper_backend.py and podlodka_turbo_backend.py
2. grep confirms _get_vad_model_dir in both files
3. grep confirms VAD initialization in load_model for both files
4. grep confirms VAD filtering in transcribe for both files
5. grep confirms Transcriber passes VAD config to all backends
6. Changes synchronized between local and RemotePackage versions
</verification>

<success_criteria>
- [ ] WhisperBackend has VAD with identical pattern to SherpaBackend
- [ ] PodlodkaBackend has VAD with identical pattern to SherpaBackend
- [ ] Transcriber passes VAD config from config.py to all backends
- [ ] All backends use same VAD model (shared models/sherpa/silero-vad directory)
- [ ] VAD behavior consistent across all backends
- [ ] Both local and RemotePackage versions updated
</success_criteria>

<output>
After completion, create `.planning/phases/02-noise-reduction-vad/02-04-SUMMARY.md`
</output>
