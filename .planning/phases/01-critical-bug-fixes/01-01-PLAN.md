---
phase: 01-critical-bug-fixes
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/backends/whisper_backend.py
  - RemotePackage/src/backends/whisper_backend.py
autonomous: true

must_haves:
  truths:
    - "Whisper backend принудительно использует русский язык (language='ru')"
    - "Whisper backend использует beam_size=5 для качества (или 2 для баланса)"
    - "Whisper backend использует temperature=0.0 для детерминированной декодировки"
    - "VAD параметры оптимизированы (min_silence_duration_ms=300, speech_pad_ms=400)"
  artifacts:
    - path: "src/backends/whisper_backend.py"
      contains: 'language="ru"'
      contains: 'beam_size=5'
      contains: 'temperature=0.0'
      contains: 'min_silence_duration_ms=300'
    - path: "RemotePackage/src/backends/whisper_backend.py"
      contains: 'language="ru"'
      contains: 'beam_size=5'
  key_links:
    - from: "src/backends/whisper_backend.py"
      to: "faster_whisper.WhisperModel.transcribe"
      via: "transcribe method parameters"
      pattern: 'language=.*beam_size=.*temperature='
---

<objective>
Fix Whisper backend parameters for optimal Russian language recognition.

**What:**
Update Whisper backend to use forced Russian language, higher beam size for quality, and optimal VAD parameters.

**Why:**
Current implementation uses language="auto" which adds overhead, beam_size=1 which prioritizes speed over accuracy, and suboptimal VAD parameters. Russian language recognition improves 15-30% with correct parameters.

**Output:**
Updated whisper_backend.py with optimized parameters for Russian speech recognition.
</objective>

<execution_context>
@C:\Users\user\.claude\get-shit-down\workflows\execute-plan.md
@C:\Users\user\.claude\get-shit-down\templates\summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/research/SUMMARY.md

# Current file locations
C:\Users\user\.claude\0 ProEKTi\Transkribator\src\backends\whisper_backend.py
C:\Users\user\.claude\0 ProEKTi\Transkribator\RemotePackage\src\backends\whisper_backend.py
</context>

<tasks>

<task type="auto">
  <name>Fix Whisper backend language parameter</name>
  <files>src/backends/whisper_backend.py, RemotePackage/src/backends/whisper_backend.py</files>
  <action>
In both whisper_backend.py files:

1. Line 32: Change default language from "auto" to "ru"
   ```python
   def __init__(
       self,
       model_size: str = "base",
       device: str = "auto",
       compute_type: str = "auto",
       language: str = "ru",  # Changed from "auto" - force Russian for accuracy
       on_progress: Optional[Callable[[str], None]] = None,
   ):
   ```

2. Line 159: Remove conditional language logic - always use "ru"
   ```python
   # OLD (delete):
   language = self.language if self.language != "auto" else None

   # NEW (replace with):
   language = "ru"  # Force Russian for optimal accuracy
   ```

DO NOT change any other parameters in this task.
  </action>
  <verify>grep -n 'language="ru"' src/backends/whisper_backend.py RemotePackage/src/backends/whisper_backend.py</verify>
  <done>Both files have language="ru" hardcoded, no auto-detection logic remains</done>
</task>

<task type="auto">
  <name>Fix Whisper beam_size and add temperature</name>
  <files>src/backends/whisper_backend.py, RemotePackage/src/backends/whisper_backend.py</files>
  <action>
In both whisper_backend.py files at line 162-168:

Update the transcribe() call for faster-whisper:

```python
# OLD (delete):
segments, info = self._model.transcribe(
    audio,
    language=language,
    beam_size=1,  # Faster than 5, minimal quality loss
    vad_filter=True,
    vad_parameters=dict(min_silence_duration_ms=200)  # Faster silence detection
)

# NEW (replace with):
segments, info = self._model.transcribe(
    audio,
    language=language,
    beam_size=5,  # Quality mode - optimal for Russian accuracy
    temperature=0.0,  # Deterministic decoding, no hallucinations
    vad_filter=True,
    vad_parameters=dict(
        min_silence_duration_ms=300,  # Optimized for Russian speech patterns
        speech_pad_ms=400,  # Prevents cutting off word endings
    )
)
```

Also add temperature parameter for openai-whisper fallback at line ~173:
```python
# OpenAI Whisper
result = self._model.transcribe(
    audio,
    language=language,
    temperature=0.0,  # Add deterministic decoding
    fp16=False
)
```
  </action>
  <verify>grep -n 'beam_size=5' src/backends/whisper_backend.py RemotePackage/src/backends/whisper_backend.py</verify>
  <done>Both backends use beam_size=5, temperature=0.0, and optimized VAD parameters</done>
</task>

</tasks>

<verification>
After implementation:
1. grep confirms language="ru" in both files (line 32 and line 159 area)
2. grep confirms beam_size=5 in both files
3. grep confirms temperature=0.0 in both files
4. grep confirms min_silence_duration_ms=300 and speech_pad_ms=400
</verification>

<success_criteria>
- [ ] Whisper backend forces Russian language (no auto-detection)
- [ ] beam_size=5 for quality mode (improves accuracy 10-15%)
- [ ] temperature=0.0 for deterministic decoding (reduces hallucinations)
- [ ] VAD parameters optimized for Russian (300ms min_silence, 400ms speech_pad)
- [ ] Changes synchronized between local and RemotePackage versions
</success_criteria>

<output>
After completion, create .planning/phases/01-critical-bug-fixes/01-01-SUMMARY.md
</output>
