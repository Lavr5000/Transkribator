# Sherpa-ONNX Integration Plan

## ğŸ¯ Goal
Integrate Sherpa-ONNX with GigaAM v2 Russian model into "Ğ“Ğ¾Ğ»Ğ¾ÑĞ¢ĞµĞºÑÑ‚" application for improved Russian speech recognition accuracy.

## ğŸ“‹ Architecture

### Multi-Backend Design
```
User Interface
    â†“
MainWindow (Backend Selection)
    â†“
Transcriber (Abstract Interface)
    â†“
â”œâ”€ WhisperBackend (current - faster-whisper)
â”‚  â”œâ”€ base model
â”‚  â”œâ”€ small/medium models
â”‚  â””â”€ whisper-podlodka-turbo model
â”‚
â””â”€ SherpaBackend (NEW - sherpa-onnx)
   â”œâ”€ GigaAM v2 Russian model
   â””â”€ Future: other Sherpa models
```

## ğŸ”„ Implementation Steps

### Phase 1: Dependencies & Setup âœ…
- [x] Research completed
- [ ] Install sherpa-onnx package
- [ ] Download GigaAM v2 model
- [ ] Create models/ directory structure

### Phase 2: Core Implementation
- [ ] Create abstract `BaseBackend` class
- [ ] Implement `SherpaBackend` class
- [ ] Refactor existing `WhisperBackend` from transcriber.py
- [ ] Add backend selection to Config
- [ ] Integrate backends into Transcriber class

### Phase 3: UI Updates
- [ ] Add backend selector dropdown to Settings tab
- [ ] Add model download manager/progress indicator
- [ ] Update tooltips and help text
- [ ] Test backend switching

### Phase 4: Testing & Optimization
- [ ] Test SherpaBackend with user's singing sample
- [ ] Compare accuracy: Whisper vs Sherpa
- [ ] Benchmark performance (speed, memory)
- [ ] Fine-tune post-processing rules for Sherpa output

### Phase 5: Documentation
- [ ] Update README with backend comparison
- [ ] Add model installation instructions
- [ ] Document backend-specific features

## ğŸ“ File Structure

```
Transkribator/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ backends/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py              # Abstract base class
â”‚   â”‚   â”œâ”€â”€ whisper_backend.py   # Current implementation
â”‚   â”‚   â””â”€â”€ sherpa_backend.py    # NEW: Sherpa-ONNX
â”‚   â”œâ”€â”€ transcriber.py           # Main orchestrator
â”‚   â”œâ”€â”€ text_processor.py        # Post-processing (existing)
â”‚   â”œâ”€â”€ config.py                # Add backend selection
â”‚   â””â”€â”€ main_window.py           # UI updates
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ whisper/
â”‚   â”‚   â”œâ”€â”€ base/
â”‚   â”‚   â”œâ”€â”€ small/
â”‚   â”‚   â””â”€â”€ podlodka-turbo/
â”‚   â””â”€â”€ sherpa/
â”‚       â””â”€â”€ giga-am-v2-ru/       # GigaAM v2 Russian model
â”‚
â””â”€â”€ scripts/
    â”œâ”€â”€ download_models.py       # Model download helper
    â””â”€â”€ test_backends.py         # Comparison testing script
```

## ğŸ”§ Technical Details

### GigaAM v2 Model Information
- **Model:** sherpa-onnx-nemo-ctc-giga-am-v2-russian-2025-04-19
- **Source:** https://huggingface.co/csukuangfj/sherpa-onnx-nemo-ctc-giga-am-v2-russian-2025-04-19
- **Size:** ~50-100MB (estimated)
- **Language:** Russian
- **Type:** CTC offline model
- **Developer:** Salute-developers (GigaAM team)

### Sherpa-ONNX Installation
```bash
pip install sherpa-onnx
```

### Backend Interface
```python
class BaseBackend(ABC):
    @abstractmethod
    def transcribe(self, audio: np.ndarray, sample_rate: int) -> Tuple[str, float]:
        """Transcribe audio to text."""
        pass

    @abstractmethod
    def load_model(self):
        """Load model into memory."""
        pass

    @abstractmethod
    def unload_model(self):
        """Unload model from memory."""
        pass
```

## ğŸ“Š Expected Results

### Accuracy Improvement
- **Current (Whisper base):** ~50% accuracy on test song
- **Expected (Sherpa GigaAM):** ~70-80% accuracy (Russian-optimized)

### Performance
- **Whisper base:** ~1-2 seconds for short audio
- **Sherpa GigaAM:** ~0.5-1 second (CTC is faster than Transformer)

## ğŸ› Known Issues & Solutions

### Issue 1: Model Download Size
**Problem:** GigaAM model may be large
**Solution:** Implement lazy loading with progress indicator

### Issue 2: Backend Switching
**Problem:** Models loaded in memory
**Solution:** Unload previous backend before loading new one

### Issue 3: Post-Processing
**Problem:** Sherpa output may have different error patterns
**Solution:** Add Sherpa-specific correction rules to text_processor.py

## ğŸš€ Rollout Plan

1. **Phase 1-2:** Core implementation (backend classes)
2. **Phase 3:** UI integration (backend selector)
3. **Phase 4:** Testing with user's audio sample
4. **Phase 5:** Documentation and final polish

## ğŸ“ Notes

- Keep existing WhisperBackend as default initially
- Make SherpaBackend opt-in during testing phase
- Eventually make Sherpa default for Russian language
- Maintain backward compatibility
